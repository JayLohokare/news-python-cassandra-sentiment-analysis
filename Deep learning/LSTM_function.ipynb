{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.models import Model, Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.utils import multi_gpu_model, to_categorical\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, Dropout, Bidirectional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "deep_input (InputLayer)      (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 300)          600000    \n",
      "_________________________________________________________________\n",
      "bilstm_1 (Bidirectional)     (None, 200, 1000)         3204000   \n",
      "_________________________________________________________________\n",
      "bilstm_2 (Bidirectional)     (None, 200, 600)          3122400   \n",
      "_________________________________________________________________\n",
      "bilstm_3 (Bidirectional)     (None, 200)               560800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "deep_output (Dense)          (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,497,403\n",
      "Trainable params: 7,497,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_len   = 200\n",
    "max_vocab = 2000\n",
    "embed_dim = 300\n",
    "hid_dim   = 500\n",
    "hid_dim2  = 300\n",
    "hid_dim3  = 100\n",
    "lstm_out  = 50\n",
    "\n",
    "# Input\n",
    "deep_input = Input(shape=(max_len, ), name = 'deep_input')\n",
    "deep_embed = Embedding(max_vocab, embed_dim, input_length = max_len)(deep_input)\n",
    "\n",
    "\n",
    "# Hidden layer\n",
    "deep_lstm = Bidirectional(LSTM(hid_dim, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True),name = 'bilstm_1')(deep_embed)\n",
    "deep_lstm = Bidirectional(LSTM(hid_dim2, dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True), name = 'bilstm_2')(deep_lstm)\n",
    "deep_lstm = Bidirectional(LSTM(hid_dim3, dropout = 0.2, recurrent_dropout = 0.2), name = 'bilstm_3')(deep_lstm)\n",
    "\n",
    "# Outputs\n",
    "deep_output = Dense(lstm_out, activation = 'relu')(deep_lstm)\n",
    "deep_output = Dense(3, activation = 'softmax', name = 'deep_output')(deep_output)\n",
    "deep_model  = Model(inputs = deep_input, outputs = deep_output)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "deep_model.compile(loss = 'categorical_crossentropy', \n",
    "                   optimizer = optimizers.Adam(lr = 1e-3), \n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function for sentiment prediction\n",
    "def predict_label(model_file, input_texts, max_vocab = 2000, max_len = 200):\n",
    "    \n",
    "    # Reload model\n",
    "    model = load_model(model_file)\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Preprocess input texts\n",
    "    tokenizer = Tokenizer(num_words = max_vocab, split = ' ', char_level = False)\n",
    "    tokenizer.fit_on_texts(input_texts.values)\n",
    "    X = tokenizer.texts_to_sequences(input_texts.values)\n",
    "    X = pad_sequences(X, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "\n",
    "    # Predict label\n",
    "    output_label = model.predict(X)\n",
    "    output_label = np.argmax(output_label, axis = 1)\n",
    "    \n",
    "    print(\"Predited labels: \", output_label)\n",
    "    \n",
    "    return(output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "embedding_1_input (InputLayer)  (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 200)          0           embedding_1_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 200)          0           embedding_1_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 200)          0           embedding_1_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 200)          0           embedding_1_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 3)            7497403     lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Concatenate)           (None, 3)            0           sequential_4[1][0]               \n",
      "                                                                 sequential_4[2][0]               \n",
      "                                                                 sequential_4[3][0]               \n",
      "                                                                 sequential_4[4][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,497,403\n",
      "Trainable params: 7,497,403\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Predited labels:  [0 2 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "all_Data = pd.read_pickle('all_Data.pkl')\n",
    "pred_labels = predict_label(model_file = 'blstm3_w_dp_gpu_200_100_1024_fold_3.h5', input_texts = all_Data['Texts'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
